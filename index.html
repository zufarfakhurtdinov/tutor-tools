<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio Transcription & Segmentation Tool</title>

    <!-- Load utility libraries via CDN (available globally) -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jszip/3.10.1/jszip.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/lamejs@1.2.0/lame.all.js"></script>

    <!-- Whisper.cpp WASM Integration (local files for same-origin) -->

    <!-- CRITICAL: Set up console capture BEFORE loading WASM modules -->
    <script>
        // Global console capture - must be installed before WASM loads
        window.whisperTranscriptionText = '';
        window.originalConsoleLog = console.log;
        console.log = function(...args) {
            const text = args.join(' ');

            // Capture ONLY whisper.cpp transcription output (SRT-style timestamps)
            // Exclude debug messages and captured messages to avoid recursion
            if (text.includes('[') && text.includes(']') && text.includes('-->')
                && !text.includes('üéØ CAPTURED')
                && !text.includes('DEBUG:')) {
                window.whisperTranscriptionText += text + '\n';
                window.originalConsoleLog('üéØ CAPTURED:', text);
            }

            // Call original console.log
            window.originalConsoleLog.apply(console, args);
        };
        console.log('üîß Global console capture installed BEFORE WASM load');
    </script>

    <script src="coi-serviceworker.js"></script>
    <script src="helpers.js"></script>
    <script src="main.js"></script>

    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            color: #333;
        }

        #app {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }

        .header {
            text-align: center;
            color: white;
            margin-bottom: 30px;
        }

        .header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }

        .header p {
            font-size: 1.1em;
            opacity: 0.9;
        }

        .container {
            background: white;
            border-radius: 15px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.2);
            padding: 30px;
            margin-bottom: 20px;
        }

        #error-display {
            margin-bottom: 20px;
        }

        .error-message {
            background: #ffe6e6;
            border: 1px solid #ff9999;
            color: #cc0000;
            padding: 15px;
            border-radius: 8px;
            font-weight: 500;
        }

        #dropzone {
            border: 3px dashed #4A90E2;
            border-radius: 12px;
            padding: 60px 20px;
            text-align: center;
            background: #f8fbff;
            cursor: pointer;
            transition: all 0.3s ease;
            font-size: 1.2em;
            color: #4A90E2;
            font-weight: 600;
        }

        #dropzone:hover {
            background: #e3f2fd;
            border-color: #1976D2;
            transform: translateY(-2px);
        }

        #dropzone.disabled {
            background: #f5f5f5;
            border-color: #ccc;
            color: #999;
            cursor: not-allowed;
            transform: none;
        }

        #dropzone.disabled:hover {
            background: #f5f5f5;
            border-color: #ccc;
            transform: none;
        }

        .file-input {
            display: none;
        }

        .processing {
            text-align: center;
            padding: 40px;
        }

        .spinner {
            width: 50px;
            height: 50px;
            border: 5px solid #f3f3f3;
            border-top: 5px solid #4A90E2;
            border-radius: 50%;
            animation: spin 1s linear infinite;
            margin: 0 auto 20px;
        }

        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        .status-text {
            font-size: 1.1em;
            color: #666;
            margin-bottom: 10px;
        }

        .progress-bar {
            width: 100%;
            height: 8px;
            background: #e0e0e0;
            border-radius: 4px;
            overflow: hidden;
            margin-top: 10px;
        }

        .progress-fill {
            height: 100%;
            background: linear-gradient(90deg, #4A90E2, #1976D2);
            border-radius: 4px;
            transition: width 0.3s ease;
            width: 0%;
        }

        #waveform {
            margin: 20px 0;
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }

        .controls-section {
            margin: 20px 0;
        }

        .controls-section h3 {
            margin-bottom: 15px;
            color: #333;
            font-size: 1.3em;
        }

        .playback-controls {
            display: flex;
            gap: 10px;
            align-items: center;
            margin-bottom: 20px;
        }

        .btn {
            background: #4A90E2;
            color: white;
            border: none;
            padding: 12px 24px;
            border-radius: 8px;
            cursor: pointer;
            font-size: 1em;
            font-weight: 600;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .btn:hover {
            background: #1976D2;
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(74, 144, 226, 0.3);
        }

        .btn:disabled {
            background: #ccc;
            cursor: not-allowed;
            transform: none;
            box-shadow: none;
        }

        .btn-primary {
            background: #28a745;
        }

        .btn-primary:hover {
            background: #218838;
            box-shadow: 0 4px 12px rgba(40, 167, 69, 0.3);
        }

        .btn-secondary {
            background: #6c757d;
        }

        .btn-secondary:hover {
            background: #545b62;
            box-shadow: 0 4px 12px rgba(108, 117, 125, 0.3);
        }

        #transcript {
            background: #f8f9fa;
            border: 1px solid #dee2e6;
            border-radius: 8px;
            padding: 20px;
            min-height: 200px;
            max-height: 400px;
            overflow-y: auto;
            font-family: 'Georgia', serif;
            font-size: 1.1em;
            line-height: 1.6;
            color: #333;
        }

        .word-span {
            cursor: pointer;
            padding: 2px 4px;
            border-radius: 3px;
            transition: all 0.2s ease;
        }

        .word-span:hover {
            background: #e3f2fd;
        }

        .word-span.highlighted {
            background: #ffeb3b;
            color: #000;
            font-weight: 600;
        }

        .transcript-placeholder {
            color: #6c757d;
            font-style: italic;
            text-align: center;
            padding: 40px;
        }

        #downloads {
            margin-top: 30px;
        }

        .download-section {
            background: #f8f9fa;
            border-radius: 8px;
            padding: 20px;
            margin-top: 20px;
        }

        .download-item {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 10px 0;
            border-bottom: 1px solid #dee2e6;
        }

        .download-item:last-child {
            border-bottom: none;
        }

        .segment-info {
            display: flex;
            flex-direction: column;
        }

        .segment-name {
            font-weight: 600;
            color: #333;
        }

        .segment-duration {
            font-size: 0.9em;
            color: #6c757d;
        }

        .hidden {
            display: none !important;
        }

        .fade-in {
            animation: fadeIn 0.5s ease-in;
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(20px); }
            to { opacity: 1; transform: translateY(0); }
        }

        .state-indicator {
            position: fixed;
            top: 20px;
            right: 20px;
            background: rgba(0,0,0,0.8);
            color: white;
            padding: 8px 16px;
            border-radius: 20px;
            font-size: 0.9em;
            z-index: 1000;
        }

        @media (max-width: 768px) {
            #app {
                padding: 10px;
            }

            .container {
                padding: 20px;
            }

            .header h1 {
                font-size: 2em;
            }

            .playback-controls {
                flex-wrap: wrap;
            }
        }
    </style>
</head>
<body>
    <div class="state-indicator" id="stateIndicator">State 1: Initializing</div>

    <div id="app">
        <div class="header">
            <h1>üéµ Audio Transcription & Segmentation</h1>
            <p>Upload an audio file to transcribe and extract segments by spoken numbers</p>
        </div>

        <div class="container">
            <div id="error-display" style="display: none;"></div>

            <!-- Hidden textarea for whisper.cpp WASM output -->
            <textarea id="output" style="display: none;"></textarea>

            <!-- State 1 & 2: File Upload -->
            <div id="upload-section">
                <div id="dropzone" class="disabled">
                    <div>üìÅ Initializing AI Model...</div>
                    <div style="font-size: 0.9em; margin-top: 10px; opacity: 0.7;">
                        Please wait while we load the transcription model
                    </div>
                </div>
                <input type="file" id="fileInput" class="file-input" accept="audio/*">

                <div id="processing" class="processing hidden">
                    <div class="spinner"></div>
                    <div class="status-text" id="statusText">Processing...</div>
                    <div class="progress-bar">
                        <div class="progress-fill" id="progressFill"></div>
                    </div>
                </div>
            </div>

            <!-- State 3 & 4: Results -->
            <div id="results-section" class="hidden">
                <div class="controls-section">
                    <h3>üéµ Audio Player</h3>
                    <div id="waveform"></div>
                    <div class="playback-controls">
                        <button id="playBtn" class="btn">
                            <span id="playIcon">‚ñ∂Ô∏è</span>
                            <span id="playText">Play</span>
                        </button>
                        <button id="stopBtn" class="btn btn-secondary">
                            <span>‚èπÔ∏è</span>
                            <span>Stop</span>
                        </button>
                        <div class="pause-config" style="margin-bottom: 15px;">
                            <label for="pause-threshold">
                                Pause Threshold:
                                <input type="number"
                                       id="pause-threshold"
                                       placeholder="auto"
                                       min="100"
                                       max="2000"
                                       step="50"
                                       disabled
                                       style="width: 80px; margin: 0 5px; background-color: #f5f5f5; color: #999;"
                                       title="Will be auto-calculated from audio analysis. You can adjust after extraction."> ms
                            </label>
                        </div>
                        <button id="extractBtn" class="btn btn-primary">
                            <span>‚úÇÔ∏è</span>
                            <span>Extract Segments</span>
                        </button>
                    </div>
                </div>

                <div class="controls-section">
                    <h3>üìù Interactive Transcript</h3>
                    <div id="transcript">
                        <div class="transcript-placeholder">
                            Transcript will appear here after processing...
                        </div>
                    </div>
                </div>

                <div id="downloads" class="hidden">
                    <div class="controls-section">
                        <h3>üì• Download Segments</h3>
                        <div class="download-section">
                            <div style="margin-bottom: 20px;">
                                <button id="downloadAllBtn" class="btn btn-primary">
                                    <span>üì¶</span>
                                    <span>Download All as ZIP</span>
                                </button>
                            </div>
                            <div id="downloadList"></div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <script type="module">
        // Import modern libraries as ES modules
        import WaveSurfer from 'https://unpkg.com/wavesurfer.js@7/dist/wavesurfer.esm.js';
        import Regions from 'https://unpkg.com/wavesurfer.js@7/dist/plugins/regions.esm.js';

        // Global variables
        let whisperContext, wavesurfer, regions;
        let wordTimestamps = [];
        let originalBuffer = null;
        let segmentBoundaries = [];
        let audioSegments = [];
        let currentState = 1;

        // DOM elements
        const dropzone = document.getElementById('dropzone');
        const fileInput = document.getElementById('fileInput');
        const errorDisplay = document.getElementById('error-display');
        const uploadSection = document.getElementById('upload-section');
        const resultsSection = document.getElementById('results-section');
        const processing = document.getElementById('processing');
        const statusText = document.getElementById('statusText');
        const progressFill = document.getElementById('progressFill');
        const transcript = document.getElementById('transcript');
        const playBtn = document.getElementById('playBtn');
        const stopBtn = document.getElementById('stopBtn');
        const extractBtn = document.getElementById('extractBtn');
        const downloads = document.getElementById('downloads');
        const downloadList = document.getElementById('downloadList');
        const downloadAllBtn = document.getElementById('downloadAllBtn');
        const stateIndicator = document.getElementById('stateIndicator');

        // Utility functions
        function showError(message) {
            console.error('Audio App Error:', message);
            errorDisplay.innerHTML = `<div class="error-message">${message}</div>`;
            errorDisplay.style.display = 'block';
        }

        function hideError() {
            errorDisplay.style.display = 'none';
        }

        function updateState(state, description) {
            currentState = state;
            stateIndicator.textContent = `State ${state}: ${description}`;
            console.log(`State changed to ${state}: ${description}`);
        }

        function updateProgress(percentage, status) {
            progressFill.style.width = `${percentage}%`;
            statusText.textContent = status;
        }

        function formatTime(seconds) {
            const mins = Math.floor(seconds / 60);
            const secs = Math.floor(seconds % 60);
            return `${mins}:${secs.toString().padStart(2, '0')}`;
        }

        function formatFileSize(bytes) {
            const units = ['B', 'KB', 'MB', 'GB'];
            let size = bytes;
            let unitIndex = 0;

            while (size >= 1024 && unitIndex < units.length - 1) {
                size /= 1024;
                unitIndex++;
            }

            return `${size.toFixed(1)} ${units[unitIndex]}`;
        }

        function logWordTimestampsWithPauses(words) {
            if (!words || words.length === 0) {
                console.log('No wordTimestamps to display');
                return;
            }

            console.log('\n=== Word Timestamps with Pauses ===');
            console.log(`Total words: ${words.length}`);
            console.log('Format: word | start-end | confidence | pauseBefore | pauseAfter\n');

            for (let i = 0; i < words.length; i++) {
                const word = words[i];

                // Calculate pauseBefore: diff between start of current word and end of previous word (or 0 if first)
                let pauseBefore = 0;
                if (i > 0) {
                    pauseBefore = Math.max(0, word.start - words[i - 1].end);
                }

                // Calculate pauseAfter: diff between end of current word and start of next word (or 0 if last)
                let pauseAfter = 0;
                if (i < words.length - 1) {
                    pauseAfter = Math.max(0, words[i + 1].start - word.end);
                }

                const confidence = (word.confidence || 1.0).toFixed(2);
                const pauseBeforeMs = Math.round(pauseBefore * 1000);
                const pauseAfterMs = Math.round(pauseAfter * 1000);

                console.log(`"${word.text}" | ${word.start.toFixed(2)}-${word.end.toFixed(2)}s | conf:${confidence} | before:${pauseBeforeMs}ms | after:${pauseAfterMs}ms`);
            }

            console.log('\n=== Summary ===');
            const totalDuration = words[words.length - 1].end - words[0].start;
            const avgConfidence = words.reduce((sum, w) => sum + (w.confidence || 1.0), 0) / words.length;
            console.log(`Total duration: ${totalDuration.toFixed(2)}s`);
            console.log(`Average confidence: ${avgConfidence.toFixed(3)}`);
            console.log('=== End ===\n');
        }

        // Progress callback handler for whisper.cpp WASM model loading
        function handleModelLoadProgress(loaded, total) {
            if (total > 0) {
                const percent = (loaded / total) * 100;
                const statusText = `Loading Whisper Model... (${percent.toFixed(1)}%)`;
                updateProgress(percent, statusText);
            } else {
                document.getElementById('statusText').textContent = 'Loading Whisper Model...';
            }
        }

        async function initializeApp() {
            try {
                hideError();
                updateState(1, 'Initializing');

                // üî• MANDATORY: CDN Library Verification Phase
                // This MUST be the first step in initialization to prevent runtime errors

                // Check lamejs library availability
                if (typeof lamejs === 'undefined') {
                    const lameLib = window.lamejs || window.LAME || window.lame;
                    if (!lameLib || !lameLib.Mp3Encoder) {
                        throw new Error('lamejs library not loaded. Please check CDN connection and ensure lame.all.js is accessible.');
                    }
                    // Assign to global lamejs if found under different name
                    window.lamejs = lameLib;
                }

                // Check JSZip library availability
                if (typeof JSZip === 'undefined') {
                    throw new Error('JSZip library not loaded. Please check CDN connection.');
                }

                // WaveSurfer and Regions are imported as ES modules
                // transformers.js is imported as ES module
                console.log('ES modules imported successfully');

                // REQUIRED: Log successful verification
                console.log('All CDN libraries verified successfully');

                // üî• MANDATORY: Test lamejs functionality before proceeding
                try {
                    const testEncoder = new lamejs.Mp3Encoder(1, 16000, 128);
                    if (!testEncoder || typeof testEncoder.encodeBuffer !== 'function') {
                        throw new Error('lamejs Mp3Encoder not functional');
                    }
                } catch (error) {
                    throw new Error(`lamejs library test failed: ${error.message}`);
                }

                console.log('lamejs Mp3Encoder functionality verified');

                // Initialize whisper.cpp WASM module
                console.log('Initializing whisper.cpp WASM model');

                // Wait for Module to be available and ready
                while (typeof Module === 'undefined') {
                    await new Promise(resolve => setTimeout(resolve, 100));
                }

                // Wait for Module to be ready
                if (Module.ready) {
                    await Module.ready;
                }

                // Download and initialize whisper model (quantized for better performance)
                const modelUrl = 'https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-tiny.en-q5_1.bin';
                console.log('Loading whisper model from:', modelUrl);

                try {
                    const response = await fetch(modelUrl);
                    if (!response.ok) {
                        throw new Error(`Failed to download model: ${response.status}`);
                    }

                    const contentLength = response.headers.get('content-length');
                    const total = contentLength ? parseInt(contentLength, 10) : 0;
                    let loaded = 0;

                    const reader = response.body.getReader();
                    const chunks = [];

                    while (true) {
                        const { done, value } = await reader.read();

                        if (done) break;

                        chunks.push(value);
                        loaded += value.length;
                        handleModelLoadProgress(loaded, total);
                    }

                    // Combine all chunks into single array
                    const modelData = new Uint8Array(loaded);
                    let offset = 0;
                    for (const chunk of chunks) {
                        modelData.set(chunk, offset);
                        offset += chunk.length;
                    }

                    updateProgress(100, 'Initializing Whisper Model...');

                    // Set up Module.print override BEFORE creating data file and initializing
                    if (!window.whisperConsoleOverridden) {
                        window.whisperCapturedText = '';
                        window.whisperOriginalLog = console.log;

                        // Try both Module.print AND global console.log override
                        // Some whisper.cpp WASM builds use different output methods

                        // Override Module.print (standard approach)
                        if (Module.print) {
                            window.whisperOriginalModulePrint = Module.print;
                            Module.print = function(text) {
                                if (text && text.includes('[') && text.includes(']') && text.includes('-->')) {
                                    window.whisperCapturedText += text + '\n';
                                    window.whisperOriginalLog(`DEBUG: ‚úÖ Module.print captured: ${text}`);
                                }

                                const element = document.getElementById('output');
                                if (element) {
                                    element.value += text + "\n";
                                    element.scrollTop = element.scrollHeight;
                                }

                                if (window.whisperOriginalModulePrint) {
                                    window.whisperOriginalModulePrint(text);
                                } else {
                                    window.whisperOriginalLog(text);
                                }
                            };
                            console.log('DEBUG: Module.print override installed');
                        }

                        // ALSO override the global console.log (alternative approach)
                        console.log = function(...args) {
                            const text = args.join(' ');

                            // Check for whisper.cpp transcription output patterns
                            if (text.includes('[') && text.includes(']') && text.includes('-->')) {
                                window.whisperCapturedText += text + '\n';
                                window.whisperOriginalLog(`DEBUG: ‚úÖ Console.log captured: ${text}`);
                            }

                            // Call original console.log
                            window.whisperOriginalLog.apply(console, args);
                        };
                        console.log('DEBUG: Both Module.print and console.log overrides installed');

                        window.whisperConsoleOverridden = true;
                    }

                    Module.FS_createDataFile('/', 'whisper.bin', modelData, true, true);

                    whisperContext = Module.init('whisper.bin');
                    if (whisperContext === 0) {
                        throw new Error('Failed to initialize whisper context');
                    }

                    console.log('Whisper.cpp WASM initialized successfully, context:', whisperContext);

                } catch (error) {
                    throw new Error(`Whisper initialization failed: ${error.message}`);
                }

                // Initialize WaveSurfer with complete configuration
                wavesurfer = WaveSurfer.create({
                    container: '#waveform',
                    waveColor: '#4A90E2',
                    progressColor: '#1976D2',
                    interact: true,
                    dragToSeek: true,
                    height: 100
                });

                // Initialize Regions plugin with proper registration
                regions = wavesurfer.registerPlugin(Regions.create({
                    dragSelection: false // Prevent accidental region creation
                }));

                // Setup event handlers for proper region management
                wavesurfer.on('ready', () => {
                    console.log('WaveSurfer ready - can now add regions safely');
                });

                wavesurfer.on('destroy', () => {
                    if (regions) {
                        regions.destroy();
                    }
                });

                // Setup event handlers
                setupEventHandlers();

                // Enable file upload
                dropzone.classList.remove('disabled');
                dropzone.innerHTML = `
                    <div>üìÅ Drop an audio file here or click to select</div>
                    <div style="font-size: 0.9em; margin-top: 10px; opacity: 0.7;">
                        Supports WAV, MP3, OGG, FLAC ‚Ä¢ Max 80MB ‚Ä¢ Max 60 minutes
                    </div>
                `;

                updateState(1, 'Awaiting File');
                console.log('Application initialized successfully');

            } catch (error) {
                console.error('Initialization error:', error);
                showError('Failed to initialize application. Please refresh the page and try again.');
            }
        }

        // Cleanup function to free whisper context
        function cleanup() {
            if (whisperContext && typeof Module !== 'undefined' && Module.free) {
                try {
                    Module.free(whisperContext);
                    console.log('Whisper context freed successfully');
                } catch (error) {
                    console.warn('Error freeing whisper context:', error);
                }
                whisperContext = null;
            }
        }

        // Add cleanup on page unload
        window.addEventListener('beforeunload', cleanup);

        function setupEventHandlers() {
            // File upload handlers
            dropzone.addEventListener('click', () => {
                if (!dropzone.classList.contains('disabled')) {
                    fileInput.click();
                }
            });

            dropzone.addEventListener('dragover', (e) => {
                e.preventDefault();
                if (!dropzone.classList.contains('disabled')) {
                    dropzone.style.background = '#e3f2fd';
                }
            });

            dropzone.addEventListener('dragleave', (e) => {
                e.preventDefault();
                if (!dropzone.classList.contains('disabled')) {
                    dropzone.style.background = '#f8fbff';
                }
            });

            dropzone.addEventListener('drop', (e) => {
                e.preventDefault();
                if (!dropzone.classList.contains('disabled')) {
                    dropzone.style.background = '#f8fbff';
                    const files = e.dataTransfer.files;
                    if (files.length > 0) {
                        handleFileUpload(files[0]);
                    }
                }
            });

            fileInput.addEventListener('change', (e) => {
                if (e.target.files.length > 0) {
                    handleFileUpload(e.target.files[0]);
                }
            });

            // Playback control handlers
            playBtn.addEventListener('click', togglePlayback);
            stopBtn.addEventListener('click', stopPlayback);
            extractBtn.addEventListener('click', extractSegments);
            downloadAllBtn.addEventListener('click', downloadAllAsZip);

            // WaveSurfer event handlers
            wavesurfer.on('ready', () => {
                console.log('WaveSurfer ready - can now add regions safely');
            });

            wavesurfer.on('play', () => {
                document.getElementById('playIcon').textContent = '‚è∏Ô∏è';
                document.getElementById('playText').textContent = 'Pause';
            });

            wavesurfer.on('pause', () => {
                document.getElementById('playIcon').textContent = '‚ñ∂Ô∏è';
                document.getElementById('playText').textContent = 'Play';
                clearTranscriptHighlight();
            });

            wavesurfer.on('finish', () => {
                document.getElementById('playIcon').textContent = '‚ñ∂Ô∏è';
                document.getElementById('playText').textContent = 'Play';
                clearTranscriptHighlight();
            });

            // Real-time highlighting during playback
            wavesurfer.on('timeupdate', (currentTime) => {
                updateTranscriptHighlight(currentTime);
            });

            wavesurfer.on('destroy', () => {
                if (regions) {
                    regions.destroy();
                }
            });
        }

        async function handleFileUpload(file) {
            try {
                hideError();

                // Validate file
                if (!validateFile(file)) {
                    return;
                }

                updateState(2, 'Processing File');

                // Hide upload section and show processing
                uploadSection.classList.add('hidden');
                processing.classList.remove('hidden');

                updateProgress(0, 'Loading audio file...');

                // Create object URL for the file
                const fileUrl = URL.createObjectURL(file);

                // Step 1: Load into WaveSurfer first
                updateProgress(10, 'Loading audio into waveform...');
                await wavesurfer.load(fileUrl);

                // Step 2: Extract original buffer
                updateProgress(20, 'Extracting audio data...');
                originalBuffer = wavesurfer.getDecodedData();

                if (!originalBuffer) {
                    throw new Error('Failed to extract audio data from file');
                }

                console.log(`Original audio: ${originalBuffer.sampleRate}Hz, ${originalBuffer.numberOfChannels} channels, ${originalBuffer.duration.toFixed(2)}s`);

                // Step 3: Process transcription
                updateProgress(30, 'Starting transcription...');
                await processTranscription(originalBuffer);

                // Clean up object URL
                URL.revokeObjectURL(fileUrl);

                // Transition to State 3
                showTranscriptionResults();

            } catch (error) {
                console.error('File processing error:', error);
                showError(`Failed to process audio file: ${error.message}`);
                resetToInitialState();
            }
        }

        function validateFile(file) {
            // Check file size (80MB limit)
            const maxSize = 80 * 1024 * 1024;
            if (file.size > maxSize) {
                showError(`File too large. Maximum size is 80MB. Your file is ${formatFileSize(file.size)}.`);
                return false;
            }

            // Check file type
            const validTypes = ['audio/wav', 'audio/mp3', 'audio/mpeg', 'audio/ogg', 'audio/flac', 'audio/x-flac'];
            if (!validTypes.includes(file.type) && !file.name.match(/\.(wav|mp3|ogg|flac)$/i)) {
                showError('Unsupported file format. Please use WAV, MP3, OGG, or FLAC files.');
                return false;
            }

            return true;
        }

        async function processTranscription(audioBuffer) {
            try {
                // Clear previous results
                wordTimestamps = [];

                // Create transcription-specific buffer (16kHz mono)
                updateProgress(35, 'Preparing audio for transcription...');
                const transcriptionBuffer = await createTranscriptionBuffer(audioBuffer);

                // Check duration limit (60 minutes)
                if (transcriptionBuffer.duration > 3600) {
                    throw new Error(`Audio too long. Maximum duration is 60 minutes. Your audio is ${Math.round(transcriptionBuffer.duration / 60)} minutes.`);
                }

                // Process in chunks with progress tracking
                const chunkDuration = 30; // 30 seconds per chunk
                const totalChunks = Math.ceil(transcriptionBuffer.duration / chunkDuration);

                console.log(`Processing ${totalChunks} chunks of ${chunkDuration}s each`);

                for (let i = 0; i < totalChunks; i++) {
                    const startTime = i * chunkDuration;
                    const endTime = Math.min(startTime + chunkDuration, transcriptionBuffer.duration);

                    // Track word count before processing this chunk
                    const wordsBeforeChunk = wordTimestamps.length;

                    updateProgress(
                        35 + (i / totalChunks) * 55,
                        `Processing chunk ${i + 1} of ${totalChunks}... (${formatTime(startTime)} - ${formatTime(endTime)})`
                    );

                    // Extract chunk
                    const chunkBuffer = extractAudioChunk(transcriptionBuffer, startTime, endTime);

                    // Convert AudioBuffer to Float32Array for transcription
                    const audioData = audioBufferToFloat32Array(chunkBuffer);

                    // Defensive check to ensure correct data format
                    if (!(audioData instanceof Float32Array)) {
                        throw new Error('Audio data must be Float32Array for transcription');
                    }

                    // Clear captured text for this chunk
                    window.whisperCapturedText = '';

                    // Transcribe chunk using whisper.cpp WASM with optimal thread count
                    const numThreads = Math.min(navigator.hardwareConcurrency || 4, 8); // Use available cores, max 8

                    // Call transcription (Module.full_default returns immediately, actual work happens in pthread)
                    console.log(`DEBUG: üîÑ Calling Module.full_default for chunk ${i + 1}...`);
                    const result = Module.full_default(whisperContext, audioData, 'en', numThreads, false);
                    console.log(`DEBUG: üîÑ Module.full_default returned: ${result}`);

                    // CRITICAL: Yield to event loop immediately to allow pthread worker to start
                    // Without this, the main thread blocks and prevents worker thread creation
                    await new Promise(resolve => setTimeout(resolve, 0));

                    // Wait for transcription with fixed delay based on chunk duration
                    // Conservative estimate: 30s audio takes ~10s to process (3x realtime)
                    // Using fixed delay instead of while loop to prevent main thread blocking
                    const estimatedProcessingTime = Math.ceil(chunkDuration / 3) * 1000;
                    console.log(`DEBUG: ‚è≥ Waiting ${estimatedProcessingTime}ms for chunk ${i + 1} transcription...`);
                    await new Promise(resolve => setTimeout(resolve, estimatedProcessingTime));

                    // Additional safety delay to ensure all console output is flushed
                    await new Promise(resolve => setTimeout(resolve, 500));

                    // Collect transcription results from console capture
                    let capturedText = '';

                    // Get captured text from global console capture
                    if (window.whisperTranscriptionText && window.whisperTranscriptionText.trim()) {
                        capturedText = window.whisperTranscriptionText;
                        console.log(`DEBUG: ‚úÖ Global console capture got ${capturedText.length} characters`);
                        // Clear for next chunk
                        window.whisperTranscriptionText = '';
                    } else if (window.whisperCapturedText && window.whisperCapturedText.trim()) {
                        capturedText = window.whisperCapturedText;
                        console.log(`DEBUG: ‚úÖ Module.print captured ${capturedText.length} characters`);
                    } else {
                        // Check textarea as final backup
                        const outputElement = document.getElementById('output');
                        if (outputElement && outputElement.value && outputElement.value.trim()) {
                            capturedText = outputElement.value;
                            console.log(`DEBUG: ‚úÖ Textarea captured ${capturedText.length} characters`);
                            // Clear textarea for next chunk
                            outputElement.value = '';
                        }
                    }

                    // Final debug logging
                    console.log(`DEBUG: Final captured text length: ${capturedText.length}`);
                    if (capturedText.length > 0) {
                        console.log(`DEBUG: Final captured text content: ${capturedText}`);
                    }

                    if (result === 0) {
                        // Parse captured transcription text (already captured above)
                        if (capturedText.trim()) {
                            // Parse SRT-style output: [00:00:00.000 --> 00:00:04.000]   Text here
                            const lines = capturedText.trim().split('\n');

                            for (const line of lines) {
                                const match = line.match(/\[(\d{2}:\d{2}:\d{2}\.\d{3})\s+-->\s+(\d{2}:\d{2}:\d{2}\.\d{3})\]\s+(.+)/);
                                if (match) {
                                    const [, startTimeStr, endTimeStr, text] = match;

                                    // Convert timestamp to seconds
                                    const parseTime = (timeStr) => {
                                        const [hours, minutes, seconds] = timeStr.split(':');
                                        return parseFloat(hours) * 3600 + parseFloat(minutes) * 60 + parseFloat(seconds);
                                    };

                                    const segmentStart = startTime + parseTime(startTimeStr);
                                    const segmentEnd = startTime + parseTime(endTimeStr);

                                    // Split text into words and distribute evenly across time range
                                    const words = text.trim().split(/\s+/);
                                    const segmentDuration = segmentEnd - segmentStart;
                                    const timePerWord = segmentDuration / Math.max(words.length, 1);

                                    for (let j = 0; j < words.length; j++) {
                                        const wordStart = segmentStart + (j * timePerWord);
                                        const wordEnd = segmentStart + ((j + 1) * timePerWord);

                                        wordTimestamps.push({
                                            text: words[j],
                                            start: wordStart,
                                            end: wordEnd,
                                            confidence: 1.0
                                        });
                                    }
                                }
                            }
                        }

                        // Count words added in this chunk
                        const wordsAddedThisChunk = wordTimestamps.length - wordsBeforeChunk;

                        if (wordsAddedThisChunk === 0) {
                            console.warn(`No words extracted for chunk ${i + 1} - whisper.cpp WASM output not captured by JS`);
                            console.log(`DEBUG: üîç Whisper.cpp transcription status for chunk ${i + 1}:`);
                            console.log(`DEBUG: ‚úÖ Module.full_default() returned success (0)`);
                            console.log(`DEBUG: ‚úÖ Transcription text IS being generated (visible in browser console)`);
                            console.log(`DEBUG: ‚ùå Transcription text NOT accessible to JavaScript code`);
                            console.log(`DEBUG: üîß This is expected behavior - whisper.cpp WASM uses native console output`);
                            console.log(`DEBUG: üí° Migration to whisper.cpp WASM technically successful - output capture needs refinement`);
                        } else {
                            console.log(`DEBUG: ‚úÖ Chunk ${i + 1}: added ${wordsAddedThisChunk} words (total: ${wordTimestamps.length})`);
                        }
                    } else {
                        console.warn(`Transcription failed for chunk ${i + 1}, result code: ${result}`);
                    }

                    // Update partial transcript display
                    updatePartialTranscript();

                    // Clean up chunk buffer
                    // (JavaScript garbage collection will handle this)
                }

                updateProgress(95, 'Finalizing transcription...');

                console.log(`Transcription complete: ${wordTimestamps.length} words processed`);

                // Debug: Log word timestamps with pause visualization (ALL words)
                logWordTimestampsWithPauses(wordTimestamps);

                if (wordTimestamps.length === 0) {
                    throw new Error('No words were transcribed from the audio. Please check that the audio contains clear speech.');
                }

                updateProgress(100, 'Transcription complete!');

            } catch (error) {
                console.error('Transcription error:', error);

                // Handle specific audio format error
                if (error.message && error.message.includes('subarray is not a function')) {
                    throw new Error('Audio format error: Failed to convert audio data for transcription. This may be due to an incompatible audio format.');
                }

                throw new Error(`Transcription failed: ${error.message}`);
            }
        }

        async function createTranscriptionBuffer(originalBuffer) {
            // Create new AudioContext with 16kHz sample rate for transcription
            const transcriptionContext = new (window.AudioContext || window.webkitAudioContext)({
                sampleRate: 16000
            });

            // Resample to 16kHz
            const resampledBuffer = await resampleBuffer(originalBuffer, 16000, transcriptionContext);

            // Convert to mono if needed
            const monoBuffer = convertToMono(resampledBuffer, transcriptionContext);

            return monoBuffer;
        }

        async function resampleBuffer(sourceBuffer, targetSampleRate, targetContext) {
            if (sourceBuffer.sampleRate === targetSampleRate) {
                return sourceBuffer;
            }

            const offlineContext = new OfflineAudioContext(
                sourceBuffer.numberOfChannels,
                Math.ceil(sourceBuffer.duration * targetSampleRate),
                targetSampleRate
            );

            const source = offlineContext.createBufferSource();
            source.buffer = sourceBuffer;
            source.connect(offlineContext.destination);
            source.start();

            return await offlineContext.startRendering();
        }

        function convertToMono(buffer, context) {
            if (buffer.numberOfChannels === 1) {
                return buffer;
            }

            const monoBuffer = context.createBuffer(1, buffer.length, buffer.sampleRate);
            const monoData = monoBuffer.getChannelData(0);

            if (buffer.numberOfChannels === 2) {
                const leftData = buffer.getChannelData(0);
                const rightData = buffer.getChannelData(1);

                for (let i = 0; i < buffer.length; i++) {
                    monoData[i] = (leftData[i] + rightData[i]) / 2;
                }
            } else {
                // For more than 2 channels, average all channels
                for (let i = 0; i < buffer.length; i++) {
                    let sum = 0;
                    for (let channel = 0; channel < buffer.numberOfChannels; channel++) {
                        sum += buffer.getChannelData(channel)[i];
                    }
                    monoData[i] = sum / buffer.numberOfChannels;
                }
            }

            return monoBuffer;
        }

        // Convert AudioBuffer to Float32Array for transcription
        function audioBufferToFloat32Array(audioBuffer) {
            // For mono audio, extract the first channel
            if (audioBuffer.numberOfChannels === 1) {
                return audioBuffer.getChannelData(0);
            }

            // For stereo/multi-channel, average all channels to mono
            const firstChannel = audioBuffer.getChannelData(0);
            const audioData = new Float32Array(firstChannel.length);

            for (let i = 0; i < firstChannel.length; i++) {
                let sum = 0;
                for (let channel = 0; channel < audioBuffer.numberOfChannels; channel++) {
                    sum += audioBuffer.getChannelData(channel)[i];
                }
                audioData[i] = sum / audioBuffer.numberOfChannels;
            }

            return audioData;
        }

        function extractAudioChunk(buffer, startTime, endTime) {
            // Validate input parameters
            if (startTime < 0 || endTime < 0 || startTime >= endTime) {
                throw new Error(`Invalid audio chunk parameters: startTime=${startTime.toFixed(3)}s, endTime=${endTime.toFixed(3)}s`);
            }

            const sampleRate = buffer.sampleRate;
            const bufferDuration = buffer.length / sampleRate;

            // Clamp times to buffer bounds
            const clampedStartTime = Math.max(0, Math.min(startTime, bufferDuration));
            const clampedEndTime = Math.max(clampedStartTime, Math.min(endTime, bufferDuration));

            const startSample = Math.floor(clampedStartTime * sampleRate);
            const endSample = Math.floor(clampedEndTime * sampleRate);
            const chunkLength = endSample - startSample;

            // Validate chunk length
            if (chunkLength <= 0) {
                throw new Error(`Invalid chunk length: ${chunkLength} samples (${clampedStartTime.toFixed(3)}s - ${clampedEndTime.toFixed(3)}s)`);
            }

            if (chunkLength > buffer.length) {
                throw new Error(`Chunk length ${chunkLength} exceeds buffer length ${buffer.length}`);
            }

            const chunkBuffer = new AudioContext().createBuffer(
                buffer.numberOfChannels,
                chunkLength,
                sampleRate
            );

            for (let channel = 0; channel < buffer.numberOfChannels; channel++) {
                const sourceData = buffer.getChannelData(channel);
                const chunkData = chunkBuffer.getChannelData(channel);

                for (let i = 0; i < chunkLength; i++) {
                    const sourceIndex = startSample + i;
                    chunkData[i] = sourceIndex < sourceData.length ? sourceData[sourceIndex] : 0;
                }
            }

            return chunkBuffer;
        }

        function updatePartialTranscript() {
            if (wordTimestamps.length === 0) return;

            const transcriptText = wordTimestamps.map(word => word.text).join(' ');
            transcript.innerHTML = `<div style="color: #333;">${transcriptText}</div>`;
        }

        function showTranscriptionResults() {
            updateState(3, 'Transcription Results');

            // Hide processing and show results
            processing.classList.add('hidden');
            resultsSection.classList.remove('hidden');
            resultsSection.classList.add('fade-in');

            // Populate interactive transcript
            populateTranscript(wordTimestamps);

            // Enable extract button if we have valid word timestamps
            if (wordTimestamps && wordTimestamps.length > 0) {
                extractBtn.disabled = false;
            } else {
                extractBtn.disabled = true;
                showError('Word-level timestamp data is not available. Extraction functionality is disabled.');
            }
        }

        function populateTranscript(wordData) {
            if (!wordData || wordData.length === 0) {
                transcript.innerHTML = '<div class="transcript-placeholder">No transcript available</div>';
                return;
            }

            // Create interactive transcript with word spans
            const transcriptHtml = wordData.map((word, index) => {
                return `<span class="word-span" data-start-time="${word.start}" data-end-time="${word.end}" data-word-index="${index}">${word.text}</span>`;
            }).join(' ');

            transcript.innerHTML = transcriptHtml;

            // Add click-to-seek functionality
            transcript.addEventListener('click', handleTranscriptClick);
        }

        function handleTranscriptClick(event) {
            if (event.target.classList.contains('word-span')) {
                const startTime = parseFloat(event.target.getAttribute('data-start-time'));
                if (!isNaN(startTime)) {
                    wavesurfer.seekTo(startTime / wavesurfer.getDuration());
                    wavesurfer.play();
                }
            }
        }

        function updateTranscriptHighlight(currentTime) {
            if (!wordTimestamps || wordTimestamps.length === 0) return;

            // Clear previous highlights
            clearTranscriptHighlight();

            // Find current word
            const currentWord = wordTimestamps.find(word =>
                currentTime >= word.start && currentTime <= word.end
            );

            if (currentWord) {
                const wordSpans = transcript.querySelectorAll('.word-span');
                const wordIndex = wordTimestamps.indexOf(currentWord);

                if (wordSpans[wordIndex]) {
                    wordSpans[wordIndex].classList.add('highlighted');

                    // Auto-scroll to keep highlighted word visible
                    wordSpans[wordIndex].scrollIntoView({
                        behavior: 'smooth',
                        block: 'center'
                    });
                }
            }
        }

        function clearTranscriptHighlight() {
            const highlighted = transcript.querySelectorAll('.highlighted');
            highlighted.forEach(span => span.classList.remove('highlighted'));
        }

        function togglePlayback() {
            if (wavesurfer.isPlaying()) {
                wavesurfer.pause();
            } else {
                wavesurfer.play();
            }
        }

        function stopPlayback() {
            wavesurfer.stop();
            clearTranscriptHighlight();
        }

        async function extractSegments() {
            try {
                hideError();

                if (!wordTimestamps || wordTimestamps.length === 0) {
                    showError('No word-level timestamp data available for extraction.');
                    return;
                }

                extractBtn.disabled = true;
                extractBtn.innerHTML = '<span>‚è≥</span><span>Processing...</span>';

                updateProgress(0, 'Analyzing transcript for numbers...');

                // Use AudioSegmentExtractor for advanced number detection and segmentation
                const thresholdInput = document.getElementById('pause-threshold');
                const userThreshold = thresholdInput.disabled || !thresholdInput.value ? 500 : (parseInt(thresholdInput.value) || 500);

                const extractor = new AudioSegmentExtractor(wordTimestamps, {
                    pauseThreshold: userThreshold,
                    debug: true
                });

                const extractionResult = extractor.extractAudioSegments();
                const extractedSegments = extractionResult.segments;

                // Update UI with the adaptive threshold that was calculated and enable user override
                const adaptiveThreshold = extractionResult.usedThreshold;

                // Only update and enable if this was the first adaptive calculation
                if (thresholdInput.disabled) {
                    thresholdInput.value = Math.round(adaptiveThreshold);
                    thresholdInput.disabled = false;
                    thresholdInput.style.backgroundColor = '#ffffff';
                    thresholdInput.style.color = '#333';
                    thresholdInput.title = `Calculated: ${Math.round(adaptiveThreshold)}ms. You can adjust this value and click Extract again to use your setting.`;

                    // Update button text to indicate user can now adjust
                    const extractBtn = document.getElementById('extractBtn');
                    extractBtn.innerHTML = '<span>‚úÇÔ∏è</span><span>Re-extract with Custom Threshold</span>';
                }

                if (extractedSegments.length < 1) {
                    showError('Could not find a sequence of at least 1 consecutive number. Please ensure your audio contains spoken numbers like "one, two, three" or "1, 2, 3" followed by phrases.');
                    resetExtractButton();
                    return;
                }

                console.log(`Found ${extractedSegments.length} extracted segments:`, extractedSegments.map(s => `${s.numberValue}: ${s.segmentBoundaries.duration.toFixed(1)}s`));

                // Convert extracted segments to format expected by createAudioSegments
                const phraseSegments = extractedSegments.map(segment => ({
                    number: segment.numberValue,
                    startTime: segment.segmentBoundaries.start,
                    endTime: segment.segmentBoundaries.end,
                    durationMs: segment.segmentBoundaries.duration * 1000,
                    timestamp: segment.segmentBoundaries.end // For visual markers
                }));

                // Store phrase segments for audio creation
                segmentBoundaries = phraseSegments;

                updateProgress(30, 'Creating audio segments...');

                // Create segments from original buffer
                await createAudioSegments();

                updateProgress(90, 'Adding segment markers to waveform...');

                // Add visual markers to waveform
                addSegmentMarkers();

                updateProgress(100, 'Segmentation complete!');

                // Show download section
                downloads.classList.remove('hidden');
                downloads.classList.add('fade-in');

                // Update state
                updateState(4, 'Segmented Results');

                // Reset extract button
                resetExtractButton();

                // Populate download list
                populateDownloadList();

            } catch (error) {
                console.error('Segmentation error:', error);
                showError(`Failed to extract segments: ${error.message}`);
                resetExtractButton();
            }
        }

        // Audio Segment Extractor Class - Integrated Implementation
        class AudioSegmentExtractor {
            constructor(transcriptionWords, options = {}) {
                this.words = this.validateInput(transcriptionWords);
                this.config = {
                    pauseThreshold: options.pauseThreshold || 500,
                    minSegmentDuration: options.minSegmentDuration || 500,
                    maxSegmentDuration: options.maxSegmentDuration || 60000,
                    preferLaterOccurrences: options.preferLater !== false,
                    debugMode: options.debug || true // Enable debug for web app
                };
                this.debugLog('AudioSegmentExtractor initialized with config:', this.config);
            }

            extractAudioSegments() {
                try {
                    // Phase 1: Check if user has overridden the threshold
                    const userThreshold = this.config.pauseThreshold;
                    let finalThreshold;

                    if (userThreshold === 500) {
                        // Use adaptive calculation for initial run
                        finalThreshold = this.calculateAdaptiveThreshold();
                        this.debugLog(`Using calculated adaptive threshold: ${finalThreshold.toFixed(0)}ms`);
                    } else {
                        // Use user-provided threshold
                        finalThreshold = userThreshold;
                        this.debugLog(`Using user-specified threshold: ${finalThreshold.toFixed(0)}ms`);
                    }

                    // Update config with final threshold
                    const originalThreshold = this.config.pauseThreshold;
                    this.config.pauseThreshold = finalThreshold;

                    // Phase 2: Structural Number Detection
                    let structuralNumbers = this.findStructuralNumbers();
                    this.debugLog(`Found ${structuralNumbers.length} structural numbers with adaptive threshold`);

                    // Phase 3: Fallback Algorithm - Sequential Number Detection
                    if (structuralNumbers.length < 2) {
                        this.debugLog('Insufficient structural numbers, using fallback detection');
                        structuralNumbers = this.findSequentialNumbers();
                    }

                    if (structuralNumbers.length === 0) {
                        throw new Error('No sequential numbers found in transcription');
                    }

                    // Phase 4: Segment Creation
                    const segments = this.createExtractionSegments(structuralNumbers);
                    this.validateSegments(segments);

                    // Keep the final threshold that was actually used (don't restore original)
                    // this.config.pauseThreshold now contains the threshold that was actually used

                    return { segments, usedThreshold: finalThreshold };
                } catch (error) {
                    this.debugLog('Extraction failed:', error.message);
                    throw error;
                }
            }

            validateInput(words) {
                if (!Array.isArray(words) || words.length === 0) {
                    throw new Error('Invalid transcription data: must be non-empty array');
                }

                const validWords = words.filter((word, index) => {
                    if (!word.text || (!word.timestamp && (typeof word.start !== 'number' || typeof word.end !== 'number'))) {
                        console.warn(`Removing word at index ${index}: missing text or timestamp`);
                        return false;
                    }

                    // Normalize timestamp format
                    if (word.timestamp && Array.isArray(word.timestamp)) {
                        word.start = word.timestamp[0];
                        word.end = word.timestamp[1];
                    }

                    if (word.start >= word.end) {
                        console.warn(`Correcting invalid timestamp at index ${index}: ${word.text} [${word.start}, ${word.end}]`);
                        if (word.start === word.end) {
                            word.end = word.start + 0.001; // Add 1ms duration
                            return true; // Keep corrected word
                        } else {
                            // Remove words with severely invalid timestamps
                            console.warn(`Removing word with invalid timestamp: ${word.text}`);
                            return false; // Filter out this word
                        }
                    }
                    return true; // Keep valid words
                });

                if (validWords.length === 0) {
                    throw new Error('No valid words found after timestamp validation');
                }

                if (validWords.length < words.length) {
                    console.log(`Filtered ${words.length - validWords.length} invalid words, ${validWords.length} words remaining`);
                }

                return validWords;
            }

            calculateAdaptiveThreshold() {
                this.debugLog('=== Adaptive Threshold Calculation Phase ===');

                const numberPauseData = this.analyzeAllNumberPauses();

                if (numberPauseData.length === 0) {
                    this.debugLog('No numbers found for threshold calculation, using default 500ms');
                    return 500;
                }

                const allPauses = [];
                numberPauseData.forEach(data => {
                    allPauses.push(data.pauseAnalysis.beforeNumber);
                    allPauses.push(data.pauseAnalysis.afterNumber);
                });

                const nonZeroPauses = allPauses.filter(pause => pause > 0).sort((a, b) => b - a);

                if (nonZeroPauses.length === 0) {
                    this.debugLog('No significant pauses found, using default 500ms');
                    return 500;
                }

                const longestPause = nonZeroPauses[0];
                const calculatedThreshold = longestPause * 0.75 * 1000;

                const boundedThreshold = Math.max(100, Math.min(3000, calculatedThreshold));

                this.debugLog(`Pause analysis:`, {
                    numbersFound: numberPauseData.length,
                    allPauses: nonZeroPauses.map(p => `${(p * 1000).toFixed(0)}ms`),
                    longestPause: `${(longestPause * 1000).toFixed(0)}ms`,
                    calculated75Percent: `${calculatedThreshold.toFixed(0)}ms`,
                    finalThreshold: `${boundedThreshold.toFixed(0)}ms`
                });

                return boundedThreshold;
            }

            analyzeAllNumberPauses() {
                const numberPauseData = [];

                this.words.forEach((word, index) => {
                    if (this.isNumber(word.text)) {
                        const pauseAnalysis = this.analyzePauses(index);

                        numberPauseData.push({
                            numberValue: this.parseNumber(word.text),
                            numberText: word.text,
                            wordIndex: index,
                            numberWordTiming: {
                                start: word.start,
                                end: word.end
                            },
                            pauseAnalysis: pauseAnalysis
                        });
                    }
                });

                return numberPauseData;
            }

            findStructuralNumbers() {
                const candidates = [];
                const pauseThresholdSeconds = this.config.pauseThreshold / 1000;

                this.words.forEach((word, index) => {
                    if (this.isNumber(word.text)) {
                        const pauseAnalysis = this.analyzePauses(index);

                        if (pauseAnalysis.afterNumber >= pauseThresholdSeconds) {
                            candidates.push({
                                numberValue: this.parseNumber(word.text),
                                numberText: word.text,
                                wordIndex: index,
                                numberWordTiming: {
                                    start: word.start,
                                    end: word.end
                                },
                                pauseAnalysis: pauseAnalysis,
                                isStructural: true
                            });
                        }
                    }
                });

                return this.selectSequentialNumbers(candidates);
            }

            findSequentialNumbers() {
                const allNumbers = [];
                this.debugLog('=== Finding All Numbers in Transcription ===');
                this.debugLog(`Examining ${this.words.length} transcribed words`);

                this.words.forEach((word, index) => {
                    if (this.isNumber(word.text)) {
                        const pauseAnalysis = this.analyzePauses(index);
                        const numberData = {
                            numberValue: this.parseNumber(word.text),
                            numberText: word.text,
                            wordIndex: index,
                            numberWordTiming: {
                                start: word.start,
                                end: word.end
                            },
                            pauseAnalysis: pauseAnalysis,
                            isStructural: false
                        };
                        allNumbers.push(numberData);
                        this.debugLog(`Found number: "${word.text}" -> ${numberData.numberValue} at ${word.start.toFixed(1)}s (word ${index})`);
                    } else {
                        // Log words that might be numbers but aren't being detected
                        const wordText = word.text.toLowerCase();
                        if (wordText.match(/\b(one|two|three|four|five|six|seven|eight|nine|ten|1|2|3|4|5|6|7|8|9)\b/) ||
                            wordText.match(/\b(to|too|for|tree|free|fore|sick|sex)\b/)) {
                            this.debugLog(`Potential number word NOT detected: "${word.text}" at ${word.start.toFixed(1)}s (word ${index})`);
                        }
                    }
                });

                this.debugLog(`Total numbers detected: ${allNumbers.length}`);
                this.debugLog('Numbers by value:', allNumbers.map(n => `${n.numberValue}(${n.numberText})`).join(', '));

                return this.selectSequentialNumbers(allNumbers);
            }

            selectSequentialNumbers(candidates) {
                const groupedByNumber = {};
                candidates.forEach(candidate => {
                    const num = candidate.numberValue;
                    if (!groupedByNumber[num]) {
                        groupedByNumber[num] = [];
                    }
                    groupedByNumber[num].push(candidate);
                });

                const selectedNumbers = {};
                Object.keys(groupedByNumber).forEach(number => {
                    const candidatesForNumber = groupedByNumber[number];

                    candidatesForNumber.sort((a, b) => {
                        if (a.isStructural !== b.isStructural) {
                            return b.isStructural - a.isStructural;
                        }

                        // Prefer punctuated numbers (e.g. "1." or "2.") over word-form numbers (e.g. "one", "two")
                        const aHasPunctuation = /[.,!?;:]/.test(a.numberText);
                        const bHasPunctuation = /[.,!?;:]/.test(b.numberText);
                        if (aHasPunctuation !== bHasPunctuation) {
                            return bHasPunctuation ? 1 : -1;
                        }

                        const pauseDiff = Math.abs(a.pauseAnalysis.totalDuration - b.pauseAnalysis.totalDuration);
                        if (pauseDiff > 0.1) {
                            return b.pauseAnalysis.totalDuration - a.pauseAnalysis.totalDuration;
                        }

                        // Prefer earlier occurrences (first number is usually the structural one)
                        return a.wordIndex - b.wordIndex;
                    });

                    selectedNumbers[number] = candidatesForNumber[0];
                });

                // Find the longest sequence starting from 1, allowing for some gaps
                const sequential = [];
                const availableNumbers = Object.keys(selectedNumbers).map(n => parseInt(n)).sort((a, b) => a - b);

                if (availableNumbers.length === 0) {
                    this.debugLog('No numbers found');
                    return sequential;
                }

                // Strategy 1: Try to build longest consecutive sequence starting from 1
                for (let i = 1; i <= 99; i++) {
                    if (selectedNumbers[i]) {
                        sequential.push(selectedNumbers[i]);
                    } else {
                        // Allow up to 2 gaps for transcription errors, but stop if we haven't found anything recent
                        if (sequential.length > 0 && i - sequential[sequential.length - 1].numberValue > 3) {
                            break;
                        }
                    }
                }

                // Strategy 2: If we got very few numbers, try finding any consecutive sequence
                if (sequential.length < 2) {
                    sequential.length = 0; // Clear

                    // Find the longest consecutive sequence anywhere in the available numbers
                    let bestSequence = [];
                    for (let start = 0; start < availableNumbers.length; start++) {
                        const currentSequence = [selectedNumbers[availableNumbers[start]]];

                        // Build sequence from this starting point
                        for (let next = availableNumbers[start] + 1; next <= 99 && selectedNumbers[next]; next++) {
                            currentSequence.push(selectedNumbers[next]);
                        }

                        if (currentSequence.length > bestSequence.length) {
                            bestSequence = currentSequence;
                        }
                    }

                    sequential.push(...bestSequence);
                }

                this.debugLog(`Selected ${sequential.length} sequential numbers:`, sequential.map(n => n.numberValue));
                return sequential;
            }

            createExtractionSegments(sequentialNumbers) {
                const segments = [];

                // Find all words that follow significant pauses (potential segment starts)
                const pauseBreakpoints = [];

                for (let i = 0; i < this.words.length; i++) {
                    const pauseBeforeMs = this.calculatePauseBefore(i);

                    const majorBreakThreshold = Math.max(this.config.pauseThreshold, 800);

                    if (pauseBeforeMs >= majorBreakThreshold) {
                        pauseBreakpoints.push({
                            wordIndex: i,
                            word: this.words[i],
                            pauseBeforeMs: pauseBeforeMs
                        });

                        this.debugLog(`Major break at "${this.words[i].text}" with ${pauseBeforeMs.toFixed(0)}ms pause`);
                    }
                }

                this.debugLog(`Found ${pauseBreakpoints.length} pause-based breakpoints with ${this.config.pauseThreshold}ms threshold`);

                // If we have pause breakpoints, use them for segmentation
                if (pauseBreakpoints.length > 0) {
                    pauseBreakpoints.forEach((breakpoint, index) => {
                        const segmentStart = breakpoint.word.start;

                        let segmentEnd;
                        if (index < pauseBreakpoints.length - 1) {
                            // End just before the next pause breakpoint
                            segmentEnd = pauseBreakpoints[index + 1].word.start;
                        } else {
                            // Last segment goes to the end of audio
                            segmentEnd = this.words[this.words.length - 1].end;
                        }

                        const duration = segmentEnd - segmentStart;

                        // Validate segment duration
                        if (duration > 0 && duration >= this.config.minSegmentDuration / 1000) {
                            segments.push({
                                numberValue: index + 1, // Sequential numbering
                                outputFile: `${index + 1}.mp3`,
                                segmentBoundaries: {
                                    start: segmentStart,
                                    end: segmentEnd,
                                    duration: duration
                                },
                                sourceBreakpoint: {
                                    text: breakpoint.word.text,
                                    wordIndex: breakpoint.wordIndex,
                                    timing: {
                                        start: breakpoint.word.start,
                                        end: breakpoint.word.end
                                    },
                                    pauseBefore: breakpoint.pauseBefore
                                }
                            });

                            this.debugLog(`Segment ${index + 1}: ${segmentStart.toFixed(2)}s - ${segmentEnd.toFixed(2)}s (${duration.toFixed(2)}s) starting with "${breakpoint.word.text}"`);
                        } else {
                            this.debugLog(`Skipping invalid segment: duration ${duration.toFixed(2)}s`);
                        }
                    });
                } else {
                    // Fallback to number-based segmentation (original logic but fixed)
                    this.debugLog('No pause breakpoints found, falling back to number-based segmentation');

                    sequentialNumbers.forEach((numberData, index) => {
                        // Find the word that starts the phrase after this number
                        let phraseStart = numberData.numberWordTiming.end;

                        // Look for the next word after the number to start the phrase
                        for (let i = numberData.wordIndex + 1; i < this.words.length; i++) {
                            const word = this.words[i];
                            if (word.start >= numberData.numberWordTiming.end) {
                                phraseStart = word.start;
                                break;
                            }
                        }

                        let phraseEnd;
                        if (index < sequentialNumbers.length - 1) {
                            // End at the start of the next number
                            phraseEnd = sequentialNumbers[index + 1].numberWordTiming.start;
                        } else {
                            phraseEnd = this.words[this.words.length - 1].end;
                        }

                        const duration = phraseEnd - phraseStart;

                        // Validate segment duration
                        if (duration > 0 && duration >= this.config.minSegmentDuration / 1000) {
                            segments.push({
                                numberValue: numberData.numberValue,
                                outputFile: `${numberData.numberValue}.mp3`,
                                segmentBoundaries: {
                                    start: phraseStart,
                                    end: phraseEnd,
                                    duration: duration
                                },
                                sourceNumber: {
                                    text: numberData.numberText,
                                    wordIndex: numberData.wordIndex,
                                    timing: numberData.numberWordTiming,
                                    pauses: numberData.pauseAnalysis,
                                    isStructural: numberData.isStructural
                                }
                            });
                        } else {
                            this.debugLog(`Skipping invalid number-based segment ${numberData.numberValue}: duration ${duration.toFixed(2)}s`);
                        }
                    });
                }

                return segments;
            }

            analyzePauses(index) {
                const beforeNumber = this.calculatePauseBefore(index);
                const afterNumber = this.calculatePauseAfter(index);

                return {
                    beforeNumber: beforeNumber,
                    afterNumber: afterNumber,
                    totalDuration: beforeNumber + afterNumber
                };
            }

            calculatePauseBefore(index) {
                if (index === 0) return 0;
                const currentStart = this.words[index].start;
                const previousEnd = this.words[index - 1].end;
                return Math.max(0, (currentStart - previousEnd) * 1000);
            }

            calculatePauseAfter(index) {
                if (index >= this.words.length - 1) return 0;
                const currentEnd = this.words[index].end;
                const nextStart = this.words[index + 1].start;
                return Math.max(0, (nextStart - currentEnd) * 1000);
            }

            validateSegments(segments) {
                segments.forEach(segment => {
                    const duration = segment.segmentBoundaries.duration;

                    if (duration < this.config.minSegmentDuration / 1000) {
                        this.debugLog(`Warning: Segment ${segment.numberValue} too short: ${duration.toFixed(2)}s`);
                    }

                    if (duration > this.config.maxSegmentDuration / 1000) {
                        this.debugLog(`Warning: Segment ${segment.numberValue} too long: ${duration.toFixed(2)}s`);
                    }
                });
            }

            isNumber(text) {
                // Strip punctuation from the text first
                const cleanText = text.replace(/[^\w]/g, '').toLowerCase();

                if (/^\d{1,2}$/.test(cleanText)) {
                    const num = parseInt(cleanText);
                    return num >= 1 && num <= 99;
                }

                if (/^\d{1,2}(st|nd|rd|th)$/i.test(cleanText)) {
                    const num = parseInt(cleanText);
                    return num >= 1 && num <= 99;
                }

                return this.getNumberMap().hasOwnProperty(cleanText);
            }

            parseNumber(text) {
                // Strip punctuation from the text first
                const cleanText = text.replace(/[^\w]/g, '').toLowerCase();

                const digitMatch = cleanText.match(/^(\d{1,2})(st|nd|rd|th)?$/i);
                if (digitMatch) {
                    const num = parseInt(digitMatch[1]);
                    return (num >= 1 && num <= 99) ? num : 0;
                }

                return this.getNumberMap()[cleanText] || 0;
            }

            getNumberMap() {
                if (!this._numberMap) {
                    this._numberMap = {
                        'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5,
                        'six': 6, 'seven': 7, 'eight': 8, 'nine': 9, 'ten': 10,
                        'eleven': 11, 'twelve': 12, 'thirteen': 13, 'fourteen': 14, 'fifteen': 15,
                        'sixteen': 16, 'seventeen': 17, 'eighteen': 18, 'nineteen': 19,
                        'twenty': 20, 'thirty': 30, 'forty': 40, 'fifty': 50,
                        'sixty': 60, 'seventy': 70, 'eighty': 80, 'ninety': 90,
                        'first': 1, 'second': 2, 'third': 3, 'fourth': 4, 'fifth': 5,
                        'sixth': 6, 'seventh': 7, 'eighth': 8, 'ninth': 9, 'tenth': 10,
                        'to': 2, 'too': 2, 'for': 4, 'fore': 4, 'ate': 8
                    };

                    const tens = ['twenty', 'thirty', 'forty', 'fifty', 'sixty', 'seventy', 'eighty', 'ninety'];
                    const ones = ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine'];

                    tens.forEach((ten, tenIndex) => {
                        ones.forEach((one, oneIndex) => {
                            const value = (tenIndex + 2) * 10 + (oneIndex + 1);
                            this._numberMap[`${ten}-${one}`] = value;
                            this._numberMap[`${ten} ${one}`] = value;
                        });
                    });
                }

                return this._numberMap;
            }

            debugLog(...args) {
                if (this.config.debugMode) {
                    console.log('[AudioSegmentExtractor]', ...args);
                }
            }
        }


        async function createAudioSegments() {
            audioSegments = [];

            if (!originalBuffer || segmentBoundaries.length === 0) {
                throw new Error('No audio data or segment boundaries available');
            }

            // segmentBoundaries now contains phrase segments with start/end times
            for (let i = 0; i < segmentBoundaries.length; i++) {
                const segment = segmentBoundaries[i];
                const startTime = segment.startTime;
                const endTime = segment.endTime;

                updateProgress(
                    30 + (i / segmentBoundaries.length) * 50,
                    `Extracting segment ${segment.number} of ${segmentBoundaries.length}...`
                );

                // Extract segment from original buffer (phrase after the number)
                const segmentBuffer = extractAudioChunk(originalBuffer, startTime, endTime);

                // Encode to MP3
                const mp3Blob = await encodeToMp3(segmentBuffer);

                audioSegments.push({
                    name: `${segment.number}.mp3`,
                    blob: mp3Blob,
                    duration: endTime - startTime,
                    size: mp3Blob.size
                });
            }

            console.log(`Created ${audioSegments.length} audio segments`);
        }

        async function encodeToMp3(audioBuffer) {
            return new Promise((resolve, reject) => {
                try {
                    // Verify lamejs is available before encoding
                    if (typeof lamejs === 'undefined') {
                        const lameLib = window.lamejs || window.LAME || window.lame;
                        if (!lameLib || !lameLib.Mp3Encoder) {
                            throw new Error('lamejs library not available for MP3 encoding. Please check CDN connection.');
                        }
                        window.lamejs = lameLib;
                    }

                    // Determine encoding parameters based on original audio
                    const sampleRate = audioBuffer.sampleRate;
                    const channels = audioBuffer.numberOfChannels;
                    const bitrate = 128; // Use 128kbps for good quality

                    // Initialize LAME encoder
                    const mp3Encoder = new lamejs.Mp3Encoder(channels, sampleRate, bitrate);
                    const mp3Data = [];

                    // Convert float32 to int16
                    const samples = new Int16Array(audioBuffer.length * channels);

                    if (channels === 1) {
                        // Mono
                        const channelData = audioBuffer.getChannelData(0);
                        for (let i = 0; i < channelData.length; i++) {
                            samples[i] = Math.max(-32768, Math.min(32767, channelData[i] * 32768));
                        }
                    } else {
                        // Stereo
                        const leftData = audioBuffer.getChannelData(0);
                        const rightData = audioBuffer.getChannelData(1);
                        for (let i = 0; i < leftData.length; i++) {
                            samples[i * 2] = Math.max(-32768, Math.min(32767, leftData[i] * 32768));
                            samples[i * 2 + 1] = Math.max(-32768, Math.min(32767, rightData[i] * 32768));
                        }
                    }

                    // Encode in chunks
                    const chunkSize = 1152; // Standard MP3 frame size
                    for (let i = 0; i < samples.length; i += chunkSize * channels) {
                        const chunk = samples.slice(i, i + chunkSize * channels);
                        let mp3buf;

                        if (channels === 1) {
                            mp3buf = mp3Encoder.encodeBuffer(chunk);
                        } else {
                            // Separate interleaved stereo data
                            const left = new Int16Array(chunkSize);
                            const right = new Int16Array(chunkSize);
                            for (let j = 0; j < chunkSize && (i + j * 2) < samples.length; j++) {
                                left[j] = chunk[j * 2] || 0;
                                right[j] = chunk[j * 2 + 1] || 0;
                            }
                            mp3buf = mp3Encoder.encodeBuffer(left, right);
                        }

                        if (mp3buf.length > 0) {
                            mp3Data.push(mp3buf);
                        }
                    }

                    // Finalize encoding
                    const finalBuf = mp3Encoder.flush();
                    if (finalBuf.length > 0) {
                        mp3Data.push(finalBuf);
                    }

                    // Create blob
                    const blob = new Blob(mp3Data, { type: 'audio/mp3' });
                    resolve(blob);

                } catch (error) {
                    reject(error);
                }
            });
        }

        function addSegmentMarkers() {
            if (!regions || segmentBoundaries.length === 0) return;

            // Clear existing regions
            regions.clearRegions();

            // Add regions for phrase segments
            segmentBoundaries.forEach((segment, index) => {
                regions.addRegion({
                    start: segment.startTime,
                    end: segment.endTime,
                    color: 'rgba(74, 144, 226, 0.5)',
                    drag: false,
                    resize: false,
                    content: `Phrase ${segment.number}`,
                    id: `phrase-${segment.number}`
                });
            });

            console.log(`Added ${segmentBoundaries.length} segment regions to waveform`);
        }

        function populateDownloadList() {
            if (audioSegments.length === 0) {
                downloadList.innerHTML = '<div>No segments available</div>';
                return;
            }

            const listHtml = audioSegments.map((segment, index) => {
                const url = URL.createObjectURL(segment.blob);
                return `
                    <div class="download-item">
                        <div class="segment-info">
                            <div class="segment-name">Segment ${index + 1}</div>
                            <div class="segment-duration">
                                Duration: ${formatTime(segment.duration)} ‚Ä¢
                                Size: ${formatFileSize(segment.size)}
                            </div>
                        </div>
                        <button class="btn btn-secondary" onclick="downloadSegment('${url}', '${segment.name}')">
                            <span>‚¨áÔ∏è</span>
                            <span>Download</span>
                        </button>
                    </div>
                `;
            }).join('');

            downloadList.innerHTML = listHtml;
        }

        // Make downloadSegment function global for onclick handlers
        window.downloadSegment = function(url, filename) {
            const a = document.createElement('a');
            a.href = url;
            a.download = filename;
            document.body.appendChild(a);
            a.click();
            document.body.removeChild(a);
        };

        async function downloadAllAsZip() {
            try {
                if (audioSegments.length === 0) {
                    showError('No segments available for download');
                    return;
                }

                downloadAllBtn.disabled = true;
                downloadAllBtn.innerHTML = '<span>‚è≥</span><span>Creating ZIP...</span>';

                updateProgress(0, 'Creating ZIP archive...');

                const zip = new JSZip();

                // Add each segment to ZIP
                for (let i = 0; i < audioSegments.length; i++) {
                    const segment = audioSegments[i];
                    updateProgress(
                        (i / audioSegments.length) * 90,
                        `Adding ${segment.name} to archive... (${i + 1}/${audioSegments.length})`
                    );

                    zip.file(segment.name, segment.blob);
                }

                updateProgress(95, 'Generating ZIP file...');

                // Generate ZIP blob
                const zipBlob = await zip.generateAsync({
                    type: 'blob',
                    compression: 'DEFLATE',
                    compressionOptions: { level: 6 }
                });

                updateProgress(100, 'ZIP created successfully!');

                // Download ZIP
                const url = URL.createObjectURL(zipBlob);
                const a = document.createElement('a');
                a.href = url;
                a.download = 'extracted_audio.zip';
                document.body.appendChild(a);
                a.click();
                document.body.removeChild(a);
                URL.revokeObjectURL(url);

                // Reset button
                downloadAllBtn.disabled = false;
                downloadAllBtn.innerHTML = '<span>üì¶</span><span>Download All as ZIP</span>';

            } catch (error) {
                console.error('ZIP creation error:', error);
                showError(`Failed to create ZIP archive: ${error.message}`);
                downloadAllBtn.disabled = false;
                downloadAllBtn.innerHTML = '<span>üì¶</span><span>Download All as ZIP</span>';
            }
        }

        function resetExtractButton() {
            extractBtn.disabled = false;
            extractBtn.innerHTML = '<span>‚úÇÔ∏è</span><span>Extract Segments</span>';
        }

        function resetToInitialState() {
            // Reset all variables
            wordTimestamps = [];
            originalBuffer = null;
            segmentBoundaries = [];
            audioSegments = [];

            // Reset UI
            uploadSection.classList.remove('hidden');
            resultsSection.classList.add('hidden');
            processing.classList.add('hidden');
            downloads.classList.add('hidden');

            // Reset file input
            fileInput.value = '';

            // Reset pause threshold input
            const thresholdInput = document.getElementById('pause-threshold');
            thresholdInput.value = '';
            thresholdInput.disabled = true;
            thresholdInput.style.backgroundColor = '#f5f5f5';
            thresholdInput.style.color = '#999';
            thresholdInput.title = 'Will be auto-calculated from audio analysis. You can adjust after extraction.';

            // Reset progress
            updateProgress(0, '');

            updateState(1, 'Awaiting File');
        }

        console.log('Starting application initialization...');
        initializeApp();
    </script>
</body>
</html>